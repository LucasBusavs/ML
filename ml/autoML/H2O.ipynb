{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cacc5cb4",
      "metadata": {
        "id": "cacc5cb4"
      },
      "outputs": [],
      "source": [
        "!pip install h2o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b0da7d",
      "metadata": {
        "id": "33b0da7d"
      },
      "outputs": [],
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "import pandas as pd\n",
        "import os\n",
        "from score import pipeline_score\n",
        "import time\n",
        "import csv\n",
        "import sys\n",
        "import io\n",
        "from google.colab import files\n",
        "\n",
        "h2o.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redireciona os prints da função\n",
        "def capturar_e_salvar_prints_em_csv(func, *args, csv_filename=\"log.csv\", **kwargs):\n",
        "    buffer = io.StringIO()\n",
        "    stdout_original = sys.stdout  # Guarda o stdout original\n",
        "    sys.stdout = buffer           # Redireciona para o buffer\n",
        "\n",
        "    try:\n",
        "        resultado = func(*args, **kwargs)\n",
        "    finally:\n",
        "        sys.stdout = stdout_original  # Restaura o stdout original\n",
        "\n",
        "    # Pega o conteúdo dos prints\n",
        "    saida = buffer.getvalue().splitlines()\n",
        "\n",
        "    # Salva em um CSV\n",
        "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"mensagem\"])\n",
        "        for linha in saida:\n",
        "            writer.writerow([linha])\n",
        "\n",
        "    return resultado\n",
        "\n",
        "\n",
        "# Listar todos os arquivos CSV na pasta\n",
        "datasets = [f for f in os.listdir() if f.endswith(\".csv\")]\n",
        "\n",
        "# Caminho do arquivo CSV onde os resultados serão armazenados\n",
        "result_csv_path = \"H2O_results.csv\"\n",
        "\n",
        "# Se o arquivo de resultados ainda não existir, cria com cabeçalho\n",
        "if not os.path.exists(result_csv_path):\n",
        "    pd.DataFrame(columns=[\"dataset\", \"test_score\", \"execution_time\"]).to_csv(result_csv_path, index=False)"
      ],
      "metadata": {
        "id": "bMVT5mt0ajEf"
      },
      "id": "bMVT5mt0ajEf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3578ca37",
      "metadata": {
        "id": "3578ca37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d161858c-68b6-4027-f821-e401bdb5fc7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodando Maternal Health Risk.csv\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |\n",
            "17:20:38.349: Project: AutoML_1_20250426_172038\n",
            "17:20:38.353: 5-fold cross-validation will be used.\n",
            "17:20:38.354: User didn't set any runtime constraints (max runtime or max models), using default 1h time limit\n",
            "17:20:38.354: Setting stopping tolerance adaptively based on the training frame: 0.03649051825844134\n",
            "17:20:38.355: Build control seed: -1 (random)\n",
            "17:20:38.369: training frame: Frame key: AutoML_1_20250426_172038_training_py_3_sid_bf12    cols: 7    rows: 751  chunks: 1    size: 7154  checksum: -8894078642253502692\n",
            "17:20:38.369: validation frame: NULL\n",
            "17:20:38.370: leaderboard frame: NULL\n",
            "17:20:38.370: blending frame: NULL\n",
            "17:20:38.370: response column: RiskLevel\n",
            "17:20:38.370: fold column: null\n",
            "17:20:38.370: weights column: null\n",
            "17:20:38.442: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "17:20:38.547: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "17:20:38.548: Disabling Algo: DeepLearning as requested by the user.\n",
            "17:20:38.551: AutoML job created: 2025.04.26 17:20:38.181\n",
            "17:20:38.552: AutoML build started: 2025.04.26 17:20:38.551\n",
            "17:20:38.642: AutoML: starting XGBoost_1_AutoML_1_20250426_172038 model training\n",
            "\n",
            "██\n",
            "17:20:51.507: New leader: XGBoost_1_AutoML_1_20250426_172038, mean_per_class_error: 0.2409417573414522\n",
            "17:20:51.514: AutoML: starting GLM_1_AutoML_1_20250426_172038 model training\n",
            "\n",
            "█\n",
            "17:20:58.994: AutoML: starting GBM_1_AutoML_1_20250426_172038 model training\n",
            "\n",
            "█\n",
            "17:21:03.144: Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.\n",
            "17:21:03.149: AutoML: starting XGBoost_2_AutoML_1_20250426_172038 model training\n",
            "\n",
            "██\n",
            "17:21:07.511: New leader: XGBoost_2_AutoML_1_20250426_172038, mean_per_class_error: 0.20734995715926305\n",
            "17:21:07.515: AutoML: starting DRF_1_AutoML_1_20250426_172038 model training\n",
            "\n",
            "███\n",
            "17:21:16.433: New leader: DRF_1_AutoML_1_20250426_172038, mean_per_class_error: 0.17118553960659222\n",
            "17:21:16.435: AutoML: starting GBM_2_AutoML_1_20250426_172038 model training\n",
            "\n",
            "█\n",
            "17:21:20.389: AutoML: starting GBM_3_AutoML_1_20250426_172038 model training\n",
            "\n",
            "█\n",
            "17:21:24.685: AutoML: starting GBM_4_AutoML_1_20250426_172038 model training\n",
            "\n",
            "██\n",
            "17:21:28.915: Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.\n",
            "17:21:28.916: Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.\n",
            "17:21:28.922: AutoML: starting XGBoost_3_AutoML_1_20250426_172038 model training\n",
            "\n",
            "█\n",
            "17:21:32.974: AutoML: starting XRT_1_AutoML_1_20250426_172038 model training\n",
            "\n",
            "███\n",
            "17:21:39.671: AutoML: starting GBM_5_AutoML_1_20250426_172038 model training\n",
            "\n",
            "█\n",
            "17:21:42.519: Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.\n",
            "17:21:42.522: Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.\n",
            "17:21:42.526: AutoML: starting XGBoost_grid_1_AutoML_1_20250426_172038 hyperparameter search\n",
            "\n",
            "██████\n",
            "17:22:26.677: New leader: XGBoost_grid_1_AutoML_1_20250426_172038_model_12, mean_per_class_error: 0.16968962049053582\n",
            "\n",
            "███████\n",
            "17:24:32.359: AutoML: starting GBM_grid_1_AutoML_1_20250426_172038 hyperparameter search\n",
            "\n",
            "██████████████████\n",
            "17:24:45.517: New leader: GBM_grid_1_AutoML_1_20250426_172038_model_5, mean_per_class_error: 0.1670041967524805\n",
            "\n",
            "████\n",
            "17:26:03.656: New leader: GBM_grid_1_AutoML_1_20250426_172038_model_41, mean_per_class_error: 0.16583464562106823\n",
            "17:26:20.89: New leader: GBM_grid_1_AutoML_1_20250426_172038_model_49, mean_per_class_error: 0.163803538326803\n",
            "17:26:49.739: Skipping StackedEnsemble 'best_of_family_4' due to the exclude_algos option or it is already trained.\n",
            "17:26:49.740: Skipping StackedEnsemble 'all_4' due to the exclude_algos option or it is already trained.\n",
            "17:26:49.742: Skipping StackedEnsemble 'best_of_family_5' due to the exclude_algos option or it is already trained.\n",
            "17:26:49.743: Skipping StackedEnsemble 'all_5' due to the exclude_algos option or it is already trained.\n",
            "17:26:49.770: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_1_20250426_172038_model_12\n",
            "17:26:49.770: AutoML: starting XGBoost_lr_search_selection_AutoML_1_20250426_172038_select model training\n",
            "\n",
            "█████████\n",
            "17:42:57.812: New leader: GBM_grid_1_AutoML_1_20250426_172038_model_49, mean_per_class_error: 0.163803538326803\n",
            "17:42:57.843: Retraining best GBM with learning rate annealing: GBM_grid_1_AutoML_1_20250426_172038_model_49\n",
            "17:42:57.843: AutoML: starting GBM_lr_annealing_selection_AutoML_1_20250426_172038_select_model model training\n",
            "17:43:01.593: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "17:43:01.601: Skipping StackedEnsemble 'best_of_family_gbm' due to the exclude_algos option or it is already trained.\n",
            "17:43:01.611: Skipping StackedEnsemble 'all_gbm' due to the exclude_algos option or it is already trained.\n",
            "17:43:01.611: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "17:43:01.612: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "17:43:01.646: AutoML: starting GBM_grid_1_AutoML_1_20250426_172038 hyperparameter search\n",
            "\n",
            "\n",
            "17:43:37.664: New leader: GBM_grid_1_AutoML_1_20250426_172038_model_78, mean_per_class_error: 0.16246764225406482\n",
            "\n",
            "\n",
            "17:46:11.608: New leader: GBM_grid_1_AutoML_1_20250426_172038_model_148, mean_per_class_error: 0.161592454498633\n",
            "\n",
            "\n",
            "17:56:33.889: New leader: GBM_grid_1_AutoML_1_20250426_172038_model_430, mean_per_class_error: 0.1613788928815626\n",
            "\n",
            "\n",
            "18:01:50.317: AutoML: starting XGBoost_grid_1_AutoML_1_20250426_172038 hyperparameter search\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "18:11:15.119: Skipping StackedEnsemble 'best_of_family' due to the exclude_algos option or it is already trained.\n",
            "18:11:15.130: Skipping StackedEnsemble 'best_N' due to the exclude_algos option or it is already trained.\n",
            "18:11:15.131: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {completion : [resume_best_grids (10g, 60w)]}]\n",
            "18:11:15.131: AutoML build stopped: 2025.04.26 18:11:15.131\n",
            "18:11:15.131: AutoML build done: built 803 models\n",
            "18:11:15.131: AutoML duration: 50 min 36.580 sec\n",
            "\n",
            "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5c92407a-2c27-47e3-b41b-7105c3cdabdf\", \"H2O_results.csv\", 508)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7331376f-84ee-4a45-bd93-e5f2496fea7d\", \"tabela Maternal Health Risk.csv\", 588)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodando AIDS Clinical Trials Group Study 175.csv\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |\n",
            "18:11:18.798: Project: AutoML_2_20250426_181118\n",
            "18:11:18.799: 5-fold cross-validation will be used.\n",
            "18:11:18.799: User didn't set any runtime constraints (max runtime or max models), using default 1h time limit\n",
            "18:11:18.799: Setting stopping tolerance adaptively based on the training frame: 0.024937733402690822\n",
            "18:11:18.799: Build control seed: -1 (random)\n",
            "18:11:18.799: training frame: Frame key: AutoML_2_20250426_181118_training_py_11_sid_bf12    cols: 24    rows: 1608  chunks: 8    size: 52120  checksum: 7227175635959498066\n",
            "18:11:18.799: validation frame: NULL\n",
            "18:11:18.799: leaderboard frame: NULL\n",
            "18:11:18.799: blending frame: NULL\n",
            "18:11:18.799: response column: cid\n",
            "18:11:18.799: fold column: null\n",
            "18:11:18.799: weights column: null\n",
            "18:11:18.800: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "18:11:18.802: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "18:11:18.802: Disabling Algo: DeepLearning as requested by the user.\n",
            "18:11:18.802: AutoML job created: 2025.04.26 18:11:18.797\n",
            "18:11:18.803: AutoML build started: 2025.04.26 18:11:18.803\n",
            "18:11:18.808: AutoML: starting XGBoost_1_AutoML_2_20250426_181118 model training\n",
            "18:11:18.809: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "██\n",
            "18:11:29.536: New leader: XGBoost_1_AutoML_2_20250426_181118, auc: 0.94092323793152\n",
            "18:11:29.537: AutoML: starting GLM_1_AutoML_2_20250426_181118 model training\n",
            "18:11:29.538: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "\n",
            "18:11:32.390: AutoML: starting GBM_1_AutoML_2_20250426_181118 model training\n",
            "18:11:32.391: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "███\n",
            "18:11:41.466: New leader: GBM_1_AutoML_2_20250426_181118, auc: 0.9427757241298149\n",
            "18:11:41.466: Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.\n",
            "18:11:41.469: AutoML: starting XGBoost_2_AutoML_2_20250426_181118 model training\n",
            "18:11:41.470: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "█\n",
            "18:11:45.402: AutoML: starting DRF_1_AutoML_2_20250426_181118 model training\n",
            "18:11:45.402: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "███\n",
            "18:11:53.520: AutoML: starting GBM_2_AutoML_2_20250426_181118 model training\n",
            "18:11:53.520: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "█\n",
            "18:11:57.596: AutoML: starting GBM_3_AutoML_2_20250426_181118 model training\n",
            "18:11:57.596: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "█\n",
            "18:12:02.617: AutoML: starting GBM_4_AutoML_2_20250426_181118 model training\n",
            "18:12:02.618: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "██\n",
            "18:12:08.266: Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.\n",
            "18:12:08.266: Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.\n",
            "18:12:08.268: AutoML: starting XGBoost_3_AutoML_2_20250426_181118 model training\n",
            "18:12:08.269: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "██\n",
            "18:12:12.501: AutoML: starting XRT_1_AutoML_2_20250426_181118 model training\n",
            "18:12:12.502: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "█\n",
            "18:12:17.552: AutoML: starting GBM_5_AutoML_2_20250426_181118 model training\n",
            "18:12:17.552: _train param, Dropping bad and constant columns: [zprior]\n",
            "\n",
            "██\n",
            "18:12:21.456: Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.\n",
            "18:12:21.456: Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.\n",
            "18:12:21.458: AutoML: starting XGBoost_grid_1_AutoML_2_20250426_181118 hyperparameter search\n",
            "\n",
            "███████\n",
            "18:13:31.671: AutoML: starting GBM_grid_1_AutoML_2_20250426_181118 hyperparameter search\n",
            "\n",
            "█████████████████████████\n",
            "18:14:09.977: New leader: GBM_grid_1_AutoML_2_20250426_181118_model_8, auc: 0.9432527682217183\n",
            "\n",
            "█\n",
            "18:15:31.573: Skipping StackedEnsemble 'best_of_family_4' due to the exclude_algos option or it is already trained.\n",
            "18:15:31.574: Skipping StackedEnsemble 'all_4' due to the exclude_algos option or it is already trained.\n",
            "18:15:31.574: Skipping StackedEnsemble 'best_of_family_5' due to the exclude_algos option or it is already trained.\n",
            "18:15:31.574: Skipping StackedEnsemble 'all_5' due to the exclude_algos option or it is already trained.\n",
            "18:15:31.575: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_2_20250426_181118_model_5\n",
            "18:15:31.575: AutoML: starting XGBoost_lr_search_selection_AutoML_2_20250426_181118_select model training\n",
            "\n",
            "███████████\n",
            "18:23:27.898: New leader: GBM_grid_1_AutoML_2_20250426_181118_model_8, auc: 0.9432527682217183\n",
            "18:23:27.958: Retraining best GBM with learning rate annealing: GBM_grid_1_AutoML_2_20250426_181118_model_8\n",
            "18:23:27.958: AutoML: starting GBM_lr_annealing_selection_AutoML_2_20250426_181118_select_model model training\n",
            "18:23:27.959: _train param, Dropping bad and constant columns: [zprior]\n",
            "18:23:31.399: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "18:23:31.400: Skipping StackedEnsemble 'best_of_family_gbm' due to the exclude_algos option or it is already trained.\n",
            "18:23:31.400: Skipping StackedEnsemble 'all_gbm' due to the exclude_algos option or it is already trained.\n",
            "18:23:31.400: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "18:23:31.401: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "18:23:31.406: AutoML: starting XGBoost_grid_1_AutoML_2_20250426_181118 hyperparameter search\n",
            "\n",
            "\n",
            "18:47:26.14: AutoML: starting GBM_grid_1_AutoML_2_20250426_181118 hyperparameter search\n",
            "\n",
            "\n",
            "18:47:51.123: New leader: GBM_grid_1_AutoML_2_20250426_181118_model_33, auc: 0.9447805702253036\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "18:59:22.900: Skipping StackedEnsemble 'best_of_family' due to the exclude_algos option or it is already trained.\n",
            "18:59:22.902: Skipping StackedEnsemble 'best_N' due to the exclude_algos option or it is already trained.\n",
            "18:59:22.902: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {completion : [resume_best_grids (10g, 60w)]}]\n",
            "18:59:22.903: AutoML build stopped: 2025.04.26 18:59:22.902\n",
            "18:59:22.903: AutoML build done: built 422 models\n",
            "18:59:22.903: AutoML duration: 48 min  4.099 sec\n",
            "\n",
            "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0ae0aa0-52d0-4662-bc17-65c51264c0f1\", \"H2O_results.csv\", 584)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bcb28ad9-3b4a-4a50-b534-0efe31587d64\", \"tabela AIDS Clinical Trials Group Study 175.csv\", 464)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodando Breast Cancer Wisconsin (Diagnostic).csv\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |\n",
            "18:59:26.632: Project: AutoML_3_20250426_185926\n",
            "18:59:26.633: 5-fold cross-validation will be used.\n",
            "18:59:26.633: User didn't set any runtime constraints (max runtime or max models), using default 1h time limit\n",
            "18:59:26.633: Setting stopping tolerance adaptively based on the training frame: 0.048795003647426664\n",
            "18:59:26.633: Build control seed: -1 (random)\n",
            "18:59:26.633: training frame: Frame key: AutoML_3_20250426_185926_training_py_19_sid_bf12    cols: 31    rows: 420  chunks: 8    size: 55538  checksum: 6253737325151822802\n",
            "18:59:26.633: validation frame: NULL\n",
            "18:59:26.633: leaderboard frame: NULL\n",
            "18:59:26.633: blending frame: NULL\n",
            "18:59:26.633: response column: Diagnosis\n",
            "18:59:26.633: fold column: null\n",
            "18:59:26.633: weights column: null\n",
            "18:59:26.633: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "18:59:26.636: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "18:59:26.636: Disabling Algo: DeepLearning as requested by the user.\n",
            "18:59:26.637: AutoML job created: 2025.04.26 18:59:26.632\n",
            "18:59:26.674: AutoML build started: 2025.04.26 18:59:26.673\n",
            "18:59:26.674: AutoML: starting XGBoost_1_AutoML_3_20250426_185926 model training\n",
            "\n",
            "█\n",
            "18:59:33.624: New leader: XGBoost_1_AutoML_3_20250426_185926, auc: 0.97953125\n",
            "18:59:33.629: AutoML: starting GLM_1_AutoML_3_20250426_185926 model training\n",
            "\n",
            "█\n",
            "18:59:35.589: New leader: GLM_1_AutoML_3_20250426_185926, auc: 0.9959615384615385\n",
            "18:59:35.592: AutoML: starting GBM_1_AutoML_3_20250426_185926 model training\n",
            "\n",
            "██\n",
            "18:59:40.279: Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.\n",
            "18:59:40.280: AutoML: starting XGBoost_2_AutoML_3_20250426_185926 model training\n",
            "\n",
            "███\n",
            "18:59:47.678: AutoML: starting DRF_1_AutoML_3_20250426_185926 model training\n",
            "\n",
            "█\n",
            "18:59:50.634: AutoML: starting GBM_2_AutoML_3_20250426_185926 model training\n",
            "\n",
            "██\n",
            "18:59:56.81: AutoML: starting GBM_3_AutoML_3_20250426_185926 model training\n",
            "\n",
            "██\n",
            "19:00:02.512: AutoML: starting GBM_4_AutoML_3_20250426_185926 model training\n",
            "\n",
            "██\n",
            "19:00:07.28: Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.\n",
            "19:00:07.28: Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.\n",
            "19:00:07.29: AutoML: starting XGBoost_3_AutoML_3_20250426_185926 model training\n",
            "\n",
            "██\n",
            "19:00:16.311: AutoML: starting XRT_1_AutoML_3_20250426_185926 model training\n",
            "19:00:18.814: AutoML: starting GBM_5_AutoML_3_20250426_185926 model training\n",
            "\n",
            "██\n",
            "19:00:22.290: Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.\n",
            "19:00:22.290: Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.\n",
            "19:00:22.291: AutoML: starting XGBoost_grid_1_AutoML_3_20250426_185926 hyperparameter search\n",
            "\n",
            "███████████████████████████████████\n",
            "19:14:03.258: AutoML: starting GBM_grid_1_AutoML_3_20250426_185926 hyperparameter search\n",
            "\n",
            "███████\n",
            "19:20:04.820: Skipping StackedEnsemble 'best_of_family_4' due to the exclude_algos option or it is already trained.\n",
            "19:20:04.820: Skipping StackedEnsemble 'all_4' due to the exclude_algos option or it is already trained.\n",
            "19:20:04.821: Skipping StackedEnsemble 'best_of_family_5' due to the exclude_algos option or it is already trained.\n",
            "19:20:04.821: Skipping StackedEnsemble 'all_5' due to the exclude_algos option or it is already trained.\n",
            "19:20:04.842: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_3_20250426_185926_model_33\n",
            "19:20:04.842: AutoML: starting XGBoost_lr_search_selection_AutoML_3_20250426_185926_select model training\n",
            "\n",
            "██\n",
            "19:31:53.492: Retraining best GBM with learning rate annealing: GBM_grid_1_AutoML_3_20250426_185926_model_78\n",
            "19:31:53.492: AutoML: starting GBM_lr_annealing_selection_AutoML_3_20250426_185926_select_model model training\n",
            "19:31:57.708: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "19:31:57.708: Skipping StackedEnsemble 'best_of_family_gbm' due to the exclude_algos option or it is already trained.\n",
            "19:31:57.709: Skipping StackedEnsemble 'all_gbm' due to the exclude_algos option or it is already trained.\n",
            "19:31:57.709: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "19:31:57.710: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "19:31:57.714: AutoML: starting GBM_grid_1_AutoML_3_20250426_185926 hyperparameter search\n",
            "\n",
            "\n",
            "19:45:42.699: AutoML: starting XGBoost_grid_1_AutoML_3_20250426_185926 hyperparameter search\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "19:52:35.759: Skipping StackedEnsemble 'best_of_family' due to the exclude_algos option or it is already trained.\n",
            "19:52:35.760: Skipping StackedEnsemble 'best_N' due to the exclude_algos option or it is already trained.\n",
            "19:52:35.760: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {completion : [resume_best_grids (10g, 60w)]}]\n",
            "19:52:35.760: AutoML build stopped: 2025.04.26 19:52:35.760\n",
            "19:52:35.760: AutoML build done: built 424 models\n",
            "19:52:35.760: AutoML duration: 53 min  9.087 sec\n",
            "\n",
            "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5c95b5c0-833e-49d2-91c9-019558ca12ff\", \"H2O_results.csv\", 662)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cc221996-d77f-489d-8518-dc3237b5a9da\", \"tabela Breast Cancer Wisconsin (Diagnostic).csv\", 464)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "for dataset in datasets:\n",
        "  if dataset == \"H2O_results.csv\":\n",
        "    continue\n",
        "  print(f\"Rodando {dataset}\")\n",
        "\n",
        "  df = h2o.import_file(dataset)\n",
        "\n",
        "  df[-1] = df[-1].asfactor()\n",
        "\n",
        "  train, test = df.split_frame(ratios=[.75], seed=42)\n",
        "\n",
        "  x = df.columns[:-1]\n",
        "  y = df.columns[-1]\n",
        "\n",
        "  aml = H2OAutoML(verbosity='info', exclude_algos=[\"StackedEnsemble\", \"DeepLearning\"])\n",
        "\n",
        "  start_time = time.time()\n",
        "  aml.train(x=x, y=y ,training_frame = train)\n",
        "  end_time = time.time()\n",
        "  execution_time = end_time - start_time\n",
        "\n",
        "  y_pred = aml.leader.predict(test).as_data_frame().iloc[:, 0]\n",
        "  y_test = test[-1].as_data_frame().values.ravel()\n",
        "  final_score = capturar_e_salvar_prints_em_csv(pipeline_score, y_test, y_pred, verbosity=True, csv_filename=f\"tabela {dataset}\")\n",
        "\n",
        "  result = {\n",
        "      \"dataset\": dataset,\n",
        "      \"test_score\": final_score,\n",
        "      \"execution_time\": execution_time,\n",
        "  }\n",
        "\n",
        "  # Adicionar ao arquivo CSV imediatamente\n",
        "  pd.DataFrame([result]).to_csv(result_csv_path, mode=\"a\", header=False, index=False)\n",
        "\n",
        "  files.download('H2O_results.csv')\n",
        "  files.download(f\"tabela {dataset}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d4c0752",
      "metadata": {
        "id": "9d4c0752"
      },
      "outputs": [],
      "source": [
        "lb = aml.leaderboard.as_data_frame\n",
        "lb.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm = aml.leader"
      ],
      "metadata": {
        "id": "JwyhsPCIevEB"
      },
      "id": "JwyhsPCIevEB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}